{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a864bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "674a3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text, ps):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [ps.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9029edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_map = {}\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def parse_file(file_path):\n",
    "    with open(file_path, 'r') as file_object:\n",
    "        current_docno = None\n",
    "        current_text = \"\"\n",
    "        text_body = False\n",
    "        for line in file_object:\n",
    "            docno_match = re.search(r'<DOCNO>(.*?)</DOCNO>', line)\n",
    "            if docno_match:\n",
    "                current_docno = docno_match.group(1).strip()\n",
    "\n",
    "            # Find TEXT\n",
    "            text_match_start = re.search(r'<TEXT>', line)\n",
    "            text_match_end = re.search(r'</TEXT>', line)\n",
    "            if text_match_start:\n",
    "                text_body = True\n",
    "                continue\n",
    "            elif text_match_end:\n",
    "                text_body = False\n",
    "                \n",
    "            if text_body:\n",
    "                current_text+= line.strip()\n",
    "            \n",
    "            # Check if both DOCNO and TEXT are found\n",
    "            if current_docno and current_text != \"\" and text_body == False:\n",
    "                text_map[current_docno] = stem_text(current_text,ps)\n",
    "                # Reset for the next document\n",
    "                current_docno = None\n",
    "                current_text = \"\"\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "793bb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('AP_DATA/ap89_collection'):\n",
    "    file_path = os.path.join('AP_DATA/ap89_collection', filename)\n",
    "    parse_file(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5dbec092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84676"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9148fe4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AP890101-0001'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docnos = list(text_map.keys())\n",
    "docnos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57b5c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_path = 'config/stoplist.txt'\n",
    "\n",
    "with open(sw_path) as file:\n",
    "    stopwords = [line.strip() for line in file]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f464d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0278fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def process_content(text):\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords]\n",
    "\n",
    "    filtered_words = [word for word in filtered_words if word not in string.punctuation]\n",
    "\n",
    "    clean_text = ' '.join(filtered_words)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59c52fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in zip(text_map.keys(), text_map.values()):\n",
    "    text_map[key] = process_content(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b35a80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84678"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "787b7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cdc61be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "print(es.ping())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f17e29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"ap89_data1\"\n",
    "\n",
    "configurations = {\n",
    "    \"settings\" : {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 1,\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"english_stop\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords_path\": \"my_stoplist.txt\"\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"stopped\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"english_stop\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "      }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fielddata\": True,\n",
    "                \"analyzer\": \"stopped\",\n",
    "                \"index_options\": \"positions\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02e83118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'ap89_data1'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.create(index=index_name, body=configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a49fd1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data(_id, text):\n",
    "    es.index(index=index_name, body={'content': text}, id=_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2675d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in text_map:\n",
    "    add_data(key, text_map[key])\n",
    "    \n",
    "print(\"All documents have been added to the index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd813a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
